{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcglwE4y5K5C",
        "outputId": "c843fa9d-7fd7-48a1-eb12-e8d90c343907"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt-get install ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GhCOHMB5nnI",
        "outputId": "e9bc36da-2ece-4502-cf2c-42ba57e3d91c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.15.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (8.5.0)\n",
            "Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import librosa\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    Input,\n",
        "    Conv1D,\n",
        "    LSTM,\n",
        "    Bidirectional,\n",
        "    Dropout,\n",
        "    BatchNormalization,\n",
        "    Dense,\n",
        "    MaxPooling1D,\n",
        "    concatenate,\n",
        "    GlobalAveragePooling1D,\n",
        "    Flatten,\n",
        ")\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.models import save_model, load_model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, recall_score, precision_score, confusion_matrix, roc_curve\n",
        "\n",
        "import seaborn as sns\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"seaborn\")\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "2lEByrrK5sGb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cl9LrJpC5xd5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OMdLGiNlI64V"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"/content/DATASET-balanced.csv\"\n",
        "df = pd.read_csv(data_path)\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "M8O5NlqI6lCP",
        "outputId": "1895b994-6158-4333-ed5f-efde011c3aec"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/DATASET-balanced.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4-2406538442.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/DATASET-balanced.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/DATASET-balanced.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(data=df, x='LABEL')\n",
        "\n",
        "for p in plt.gca().patches:\n",
        "    plt.text(p.get_x() + p.get_width() / 2, p.get_height() + 0.1, int(p.get_height()),\n",
        "             ha='center', va='bottom')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jmUUnwQK6sII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "df['LABEL'] = label_encoder.fit_transform(df['LABEL'])"
      ],
      "metadata": {
        "id": "kVFDWSrU6ub6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['LABEL']\n",
        "X = df.drop('LABEL', axis = 1)\n",
        "for column in X:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.histplot(data=df, x=column, hue='LABEL', kde=True, palette=['blue', 'orange'])\n",
        "    plt.title(f'Distribution of {column}')\n",
        "    plt.xlabel(column)\n",
        "    plt.ylabel('Count')\n",
        "    plt.legend(labels=['FAKE', 'REAL'])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "G9-_smoh67h1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correlation_matrix = df.corr()\n",
        "plt.figure(figsize=(20, 8))\n",
        "sns.heatmap(correlation_matrix, cmap='coolwarm', annot = True)\n",
        "plt.title('Correlation Matrix')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lAYdw_c37CH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(X, window_size = 10):\n",
        "\n",
        "    data = []\n",
        "\n",
        "    for i in range(len(X)):\n",
        "        row = X.iloc[i].values\n",
        "        row_data = []\n",
        "        for j in range(len(row) - window_size):\n",
        "            window = row[j : j + window_size]\n",
        "            row_data.append(window)\n",
        "        data.append(row_data)\n",
        "\n",
        "    return np.array(data)"
      ],
      "metadata": {
        "id": "jF-CmPT07NwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.iloc[:, :] = MinMaxScaler().fit_transform(X)\n",
        "new_X = prepare_data(X, window_size = 5)"
      ],
      "metadata": {
        "id": "KABj4-aK7R5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(new_X, y.values, test_size=0.2, shuffle = True, stratify = y.values, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, shuffle = True, stratify = y_train, random_state=42)"
      ],
      "metadata": {
        "id": "Sx2iJ2ex7T5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Input, LSTM, Dropout, Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import BinaryCrossentropy\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "input_shape = (X_train.shape[1], X_train.shape[2])\n",
        "model.add(Input(shape=input_shape))\n",
        "\n",
        "# First LSTM layer\n",
        "model.add(LSTM(64, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Second LSTM layer\n",
        "model.add(LSTM(64, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Third LSTM layer\n",
        "model.add(LSTM(64, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Fourth LSTM layer\n",
        "model.add(LSTM(64, return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# First Dense layer\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Second Dense layer\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss=BinaryCrossentropy(), metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "lOuE21fx7V7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax = sns.heatmap(confusion_matrix(y_test, y_pred), annot= True, fmt='.4g')\n",
        "ax.xaxis.set_ticklabels(['Fake', 'Real'])\n",
        "ax.yaxis.set_ticklabels(['Fake', 'Real'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kHlsBGYNdx_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "callback = [\n",
        "    ModelCheckpoint(filepath='model.keras', save_best_only=True, monitor='val_loss', mode='min', verbose=1),\n",
        "    EarlyStopping(monitor='val_loss', patience=10, baseline=None, restore_best_weights=True, verbose=1)\n",
        "]"
      ],
      "metadata": {
        "id": "rdz7lHyt7Yta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, batch_size=32, epochs=60, validation_data = (X_val, y_val), callbacks = callback)"
      ],
      "metadata": {
        "id": "ssy9F98z7cw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.round(model.predict(X_test).flatten())\n"
      ],
      "metadata": {
        "id": "akIawUJv7jrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('model.keras')"
      ],
      "metadata": {
        "id": "cemqXLxN713L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "8cACethP75U2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy: \", accuracy)\n",
        "print(\"F1 Score: \", f1)\n",
        "print(\"Recall: \", recall)\n",
        "print(\"Precision: \", precision)"
      ],
      "metadata": {
        "id": "ShhTvETC77qp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']"
      ],
      "metadata": {
        "id": "FwHH0Xdt8CUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "EPOCHS = len(acc)\n",
        "plt.plot(range(EPOCHS), acc, label='Training Accuracy')\n",
        "plt.plot(range(EPOCHS), val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(EPOCHS), loss, label='Training Loss')\n",
        "plt.plot(range(EPOCHS), val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CJjCGavV8Xtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.ndimage import gaussian_filter1d\n",
        "\n",
        "sacc = gaussian_filter1d(acc, sigma=2)\n",
        "sval_acc = gaussian_filter1d(val_acc, sigma=2)\n",
        "\n",
        "sloss = gaussian_filter1d(loss, sigma=2)\n",
        "sval_loss = gaussian_filter1d(val_loss, sigma=2)\n",
        "plt.figure(figsize=(14, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(EPOCHS), sacc, label='Training Accuracy')\n",
        "plt.plot(range(EPOCHS), sval_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy (Smoothed)')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(EPOCHS), sloss, label='Training Loss')\n",
        "plt.plot(range(EPOCHS), sval_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss (Smoothed)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j1U_agNo8ZkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ==== INPUTS ====\n",
        "audio_path = \"/content/FAKE.mp3\"  # Change this to your file path\n",
        "label_value = \"REAL\"  # Set this to your label (e.g., \"REAL\" or \"FAKE\")\n",
        "\n",
        "# ==== LOAD AUDIO ====\n",
        "y, sr = librosa.load(audio_path, sr=None)\n",
        "\n",
        "# ==== EXTRACT FEATURES ====\n",
        "chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
        "chroma_stft_mean = np.mean(chroma, axis=0).reshape(-1, 1)\n",
        "\n",
        "rms = librosa.feature.rms(y=y).T\n",
        "spec_centroid = librosa.feature.spectral_centroid(y=y, sr=sr).T\n",
        "spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr).T\n",
        "rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr).T\n",
        "zcr = librosa.feature.zero_crossing_rate(y).T\n",
        "mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20).T\n",
        "\n",
        "# ==== TRIM ALL TO SAME FRAME COUNT ====\n",
        "min_frames = min(\n",
        "    chroma_stft_mean.shape[0],\n",
        "    rms.shape[0],\n",
        "    spec_centroid.shape[0],\n",
        "    spec_bw.shape[0],\n",
        "    rolloff.shape[0],\n",
        "    zcr.shape[0],\n",
        "    mfccs.shape[0]\n",
        ")\n",
        "\n",
        "chroma_stft_mean = chroma_stft_mean[:min_frames]\n",
        "rms = rms[:min_frames]\n",
        "spec_centroid = spec_centroid[:min_frames]\n",
        "spec_bw = spec_bw[:min_frames]\n",
        "rolloff = rolloff[:min_frames]\n",
        "zcr = zcr[:min_frames]\n",
        "mfccs = mfccs[:min_frames]\n",
        "\n",
        "# ==== COMBINE FEATURES ====\n",
        "features = np.hstack((\n",
        "    chroma_stft_mean,   # 1\n",
        "    rms,                # 1\n",
        "    spec_centroid,      # 1\n",
        "    spec_bw,            # 1\n",
        "    rolloff,            # 1\n",
        "    zcr,                # 1\n",
        "    mfccs               # 20\n",
        "))  # Final shape: (min_frames, 26)\n",
        "\n",
        "# ==== CREATE COLUMN NAMES ====\n",
        "column_names = [\n",
        "    \"chroma_stft\",\n",
        "    \"rms\",\n",
        "    \"spectral_centroid\",\n",
        "    \"spectral_bandwidth\",\n",
        "    \"rolloff\",\n",
        "    \"zero_crossing_rate\"\n",
        "] + [f\"mfcc_{i+1}\" for i in range(20)]\n",
        "\n",
        "# ==== CREATE DATAFRAME ====\n",
        "df = pd.DataFrame(features, columns=column_names)\n",
        "\n",
        "# ==== ADD LABEL COLUMN ====\n",
        "df[\"LABEL\"] = label_value\n",
        "\n",
        "# ==== SAVE TO CSV ====\n",
        "df.to_csv(\"FAKE\", index=False)\n",
        "\n",
        "print(\"‚úÖ Saved 'final_audio_features_27cols.csv' with 26 features + 1 label column.\")"
      ],
      "metadata": {
        "id": "m30asgDlPxDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load your trained model\n",
        "model = load_model(\"/content/model.keras\")  # Update path if needed\n",
        "\n",
        "# Load extracted features\n",
        "df = pd.read_csv(\"/content/FAKE\")\n",
        "\n",
        "# Select only the first 5 feature columns (excluding the label)\n",
        "X = df.drop(\"LABEL\", axis=1).iloc[:, :5].values  # shape: (timesteps, 5)\n",
        "\n",
        "# Reshape to 3D: (1, timesteps, 5)\n",
        "X = X.reshape(1, X.shape[0], X.shape[1])  # (1, frames, 5)\n",
        "\n",
        "# Predict\n",
        "prediction = model.predict(X)\n",
        "\n",
        "print(\"Prediction output:\", prediction)\n",
        "\n",
        "# If binary classification (e.g., real vs fake):\n",
        "if prediction[0][0] > 0.5:\n",
        "    print(\"üé≠ FAKE Audio\")\n",
        "else:\n",
        "    print(\"üé§ REAL Audio\")\n"
      ],
      "metadata": {
        "id": "D85kF90Y8cvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model, Model\n",
        "\n",
        "# Load your trained model\n",
        "model = load_model(\"/content/model.keras\")\n",
        "\n",
        "# Build an embedding extractor up to the second-to-last layer\n",
        "\n",
        "# Load features from your single test audio\n",
        "df_test = pd.read_csv(\"/content/FAKE\")\n",
        "X = df_test.drop(\"LABEL\", axis=1).iloc[:, :5].values\n",
        "X = X.reshape(1, X.shape[0], X.shape[1])\n",
        "\n",
        "# Extract embeddings and reduce to a single vector by averaging over frames\n",
        "emb_test = model.predict(X).mean(axis=1).flatten()\n",
        "\n",
        "# Load a single real/reference audio sample for baseline comparison\n",
        "df_real = pd.read_csv(\"/content/audio_features\")\n",
        "X_ref = df_real.drop(\"LABEL\", axis=1).iloc[:, :5].values\n",
        "X_ref = X_ref.reshape(1, X_ref.shape[0], X_ref.shape[1])\n",
        "emb_real = model.predict(X_ref).mean(axis=1).flatten()\n",
        "\n",
        "# Compute Euclidean distance between test and reference embeddings\n",
        "dist = np.linalg.norm(emb_test - emb_real)\n",
        "print(f\"Euclidean distance to real baseline: {dist:.4f}\")\n",
        "\n",
        "# Print result using threshold comparison\n",
        "threshold = 0.5  # adjust based on your validation set\n",
        "if dist > threshold:\n",
        "    print(\"üé≠ FAKE Audio\")\n",
        "else:\n",
        "    print(\"üé§ REAL Audio\")\n"
      ],
      "metadata": {
        "id": "IsnFWFbG8gKq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}